# -*- coding: utf-8 -*-
"""get_prediction_std.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Hsy2D5DES0xSmnMoLqDP7iqzh-wobB9T
"""

!apt-get install -y -qq software-properties-common python-software-properties module-init-tools
!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null
!apt-get update -qq 2>&1 > /dev/null
!apt-get -y install -qq google-drive-ocamlfuse fuse
from google.colab import auth
auth.authenticate_user()
from oauth2client.client import GoogleCredentials
creds = GoogleCredentials.get_application_default()
import getpass
!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL
vcode = getpass.getpass()
!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}

!mkdir -p drive
!google-drive-ocamlfuse drive
import os

# 此处为google drive中的文件路径,drive为之前指定的工作根目
#os.chdir("ColabData")
os.chdir("drive/ColabData") 
!ls

#%%
import matplotlib.pyplot as plt
import numpy as np
import glob
import skimage.io as io
from sklearn.metrics import confusion_matrix
from keras.models import load_model
import cv2
def adjust_image(img):   
    if(np.max(img) > 1):
        img = img / 255.0
    return img

def adjust_mask(prediction,threshold):
    
    prediction[prediction>=threshold]=1
    prediction[prediction<threshold]=0
    prediction=np.uint8(prediction)

    return prediction

def slice_data(image,row,col,size_image):
    '''slice whole images into (row*col)*256*256 sub images '''
    image_array=[]
    for i in range(row):
        for j in range(col):
            image_array.append(image[i*size_image:(i+1)*size_image,j*size_image:(j+1)*size_image])
    image_array=np.array(image_array)
   
    return image_array


def read_images_slice(path,size_image,whole_tissue):
    all_images_array=[]
    all_images_path=glob.glob(path)
    num_images=len(all_images_path)
    if whole_tissue:
        for i in range(1,11):
           
            im=adjust_image(io.imread(path[:-1]+'ori ('+str(i)+').png',as_gray=True))
            #print(path[:-1]+'ori('+str(i+1)+').png')
            m,n=im.shape
            row=np.floor(m/size_image).astype(int)
            col=np.floor(n/size_image).astype(int)
            all_images_array.append(slice_data(im,row,col,size_image))
    else:
        for i in all_images_path:
            im=adjust_image(io.imread(i,as_gray=True))
            m,n=im.shape
            row=np.floor(m/size_image).astype(int)
            col=np.floor(n/size_image).astype(int)
            all_images_array.append(slice_data(im,row,col,size_image))
        

    all_images_array=np.array(all_images_array)
    print(all_images_array.shape)
    all_images_array=np.expand_dims(np.concatenate(all_images_array,axis=0),axis=3)
    print(all_images_array.shape)

    #np.save('E:/pyramidal/jingCode/test',all_images_array)
    return row,col,num_images,all_images_array
def read_image(path,whole_tissue):
    all_images_array=[]
    all_images_path=glob.glob(path)
    num_images=len(all_images_path)
    if whole_tissue:
        for i in range(num_images):
            im=adjust_image(io.imread(path[:-1]+'ori('+str(i+1)+').png',as_gray=True))
    else:
        for i in all_images_path:
            im=adjust_image(io.imread(i,as_gray=True))
    all_images_array.append(im)
    all_images_array=np.array(all_images_array)
    return all_images_array

def reconstruct(row,col,num_image,all_masks_array):
    all_masks_array=np.squeeze(all_masks_array)
    all_image=[]
    for i in range(num_image):
        print(i)
        image=[]
        for j in range(row):
            image.append(np.concatenate(all_masks_array[((i*(row*col))+j*col):((i*(row*col))+(j+1)*col),:],axis=1))
        image=np.array(image)
        image=np.concatenate(image,0)
        
        all_image.append(image)
    all_image=np.array(all_image)
    print(all_image.shape)
    return all_image
def dilation_erotion(stack_imgs,kernel_size):

    if len(stack_imgs.shape)==4:
        stack_imgs=np.squeeze(stack_imgs)
        
    else:
        dx,dy,dz=stack_imgs.shape
        for i in range(dz):
            print(i)
            img=stack_imgs[:,:,i]
            kernel = np.ones((kernel_size,kernel_size),np.uint8)
            dilation = cv2.dilate(img,kernel,iterations = 1)
            stack_imgs[:,:,i] = cv2.erode(dilation,kernel,iterations = 1)
    return stack_imgs
def precision_recall(ori_mask, pred_mask,save_image):
    ori_mask=np.uint8(ori_mask)
    
    pred_mask=np.uint8(pred_mask)
    
    if np.max(ori_mask)>1:
        ori_mask=ori_mask/255
        ori_mask=np.uint8(ori_mask)
    if np.max(pred_mask)>1:
        pred_mask=pred_mask/255
        pred_mask=np.uint8(pred_mask)
    
    pred_centroid=np.round(cv2.connectedComponentsWithStats(pred_mask)[3]).astype(int)[1:]
 
    ori_centroid=np.round(cv2.connectedComponentsWithStats(ori_mask)[3]).astype(int)[1:]
    
    if save_image:
        
        plt.axis('off')
        plt.imshow(ori_mask,cmap='gray')
        #plt.savefig(str(pred_centroid.shape[0])+'cellsori.png')
        plt.imsave(str(pred_centroid.shape[0])+'cellsori.png',ori_mask,cmap='gray')
        plt.scatter(ori_centroid[:,0],ori_centroid[:,1],s=2,marker='.',c='red')
        plt.axis('off')
        plt.savefig(str(pred_centroid.shape[0])+'cellsoriWithMarker.png')
        plt.show()
        
        plt.axis('off')
        plt.imshow(pred_mask, cmap='gray') 
        #plt.savefig(str(pred_centroid.shape[0])+'cells.png')
        plt.imsave(str(pred_centroid.shape[0])+'cells.png',pred_mask,cmap='gray')
        plt.scatter(pred_centroid[:,0],pred_centroid[:,1],s=2,marker='.',c='red')
        plt.axis('off')
        plt.savefig(str(pred_centroid.shape[0])+'cellsWithMarker.png')
        plt.show()
       
        plt.axis('off')
        plt.imshow(pred_mask, cmap='gray') 
        plt.scatter(ori_centroid[:,0],ori_centroid[:,1],s=2,marker='.',c='red')
        plt.axis('off')
        plt.savefig(str(pred_centroid.shape[0])+'predcellsWithgroundcen.png')
        plt.show()
        
        plt.axis('off')
        plt.imshow(ori_mask,cmap='gray')
        plt.savefig(str(pred_centroid.shape[0])+'cellsori.png')
        plt.scatter(pred_centroid[:,0],pred_centroid[:,1],s=2,marker='.',c='red')
        plt.axis('off')
        plt.savefig(str(pred_centroid.shape[0])+'groundtruthwithpredcen.png')
        plt.show()
   

    #precision
    i=pred_mask[pred_centroid[:,1],pred_centroid[:,0]]
    index=np.where(i==1)[0]
    #predict positive
    tp_fp=np.sum(i[index])
  
    j=ori_mask[pred_centroid[:,1],pred_centroid[:,0]]
    true_positive=np.sum(j)
    precision=true_positive/tp_fp
    
    
    #recall
    #actual positive
    k=pred_mask[ori_centroid[:,1],ori_centroid[:,0]]
    tp_fn=np.sum(k==0)+true_positive
    recall=true_positive/tp_fn
    F1=2*precision*recall/(precision+recall)
    return [precision, recall,F1]


def cal_cm(y_true,y_pred):
    y_true=np.array(y_true==0)
    y_pred=np.array(y_pred==0)
    
    assert(y_true.shape==y_pred.shape)
    if np.max(y_true)>1:
        y_true=np.uint8(y_true/255)
    if np.max(y_pred)>1:
        y_pred=np.uint8(y_pred/255)
    cm=confusion_matrix(y_true.flatten(),y_pred.flatten())
    return cm
def save_image(image_arrays):
    
    print(image_arrays.shape)
    #image_arrays=np.squeeze(image_arrays)
    num_image=image_arrays.shape[0]
    for i in range(10):
       
        plt.imsave('099pred'+str(i+1)+'.png',image_arrays[i],cmap='gray')

import tensorflow as tf
from keras import backend as K
from keras.losses import binary_crossentropy
from keras import backend as K
from keras import backend 
from keras.models import Model
from keras import models
from keras import layers
from keras.layers import Input, BatchNormalization, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, concatenate, Concatenate, UpSampling2D, Activation
from keras.losses import binary_crossentropy
from functools import partial
from keras.layers import Lambda
from keras.applications.densenet import DenseNet121
import keras
import numpy as np
from keras.optimizers import Adam
from keras.layers.core import Dropout
from keras.callbacks import ModelCheckpoint
from keras import applications
#%%
#path='E:/pyramidal/jingCode/099_00_800nm_newScanner_Part1_code_data/099_00_800nm_newScanner_Part1/*'
path='drive/test/images/*'
size_image=256
whole_tissue=True
row,col,num_images,all_sub_images=read_images_slice(path,size_image,whole_tissue)
print('We have %d images in total.'%num_images)
print('Each image is split into %d rows and %d columns sub images with size 256*256.'%(row,col))
print(np.max(all_sub_images))
print(num_images)
def focal_loss(y_true, y_pred):
   gamma =2.0
   alpha = 0.25
   pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))
   pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))
   return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1))-K.sum((1-alpha) * K.pow( pt_0, gamma) * K.log(1. - pt_0))


def dice_coef(y_true, y_pred, smooth=1):
    """
    Dice = (2*|X & Y|)/ (|X|+ |Y|)
         =  2*sum(|A*B|)/(sum(A^2)+sum(B^2))
    ref: https://arxiv.org/pdf/1606.04797v1.pdf
    """
    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)
    return (2. * intersection + smooth) / (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)

def dice_coef_loss(y_true, y_pred):
    return 1-dice_coef(y_true, y_pred)

def softmax_dice_loss(y_true, y_pred):
    return binary_crossentropy(y_true, y_pred) * 0.5 + dice_coef_loss(y_true, y_pred) * 0.5# + dice_coef_loss(y_true[..., 1], y_pred[..., 1]) * 0.2




from keras.models import load_model
model = load_model('05-0.0147.hdf5',custom_objects={'dice_coef_loss':dice_coef_loss,'softmax_dice_loss':softmax_dice_loss})

prediction=model.predict(all_sub_images, batch_size=20, verbose=1)
prediction1=adjust_mask(prediction,0.5)
pred_masks=reconstruct(row,col,10,prediction1)
print(pred_masks.shape)
save_image(pred_masks)